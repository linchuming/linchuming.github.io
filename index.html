<!DOCTYPE HTML>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chuming Lin(林楚铭)</title>
  
  <meta name="author" content="Chuming Lin">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name><strong><font size="4px">Chuming Lin(林楚铭)</font></strong></name>
              </p>
              <p>I am a Researcher at Tencent Youtu Lab, where I work on computer vision and machine learning.
              </p>
              <p>
              I got my Ph.D. degree from the Department of Computer Science and Engineering, Nanjing University of Science & Technology (NUST) in 2017, and my advisor is Prof. <a href="http://www.patternrecognition.cn/~jian/">Jian Yang</a>. In 2016, I spent 6 wonderful months as a visiting student at Prof. <a href="http://www.cse.msu.edu/~liuxm/">Xiaoming Liu</a>'s lab in Michigan State University. 

              <p style="text-align:center">
                <a href="mailto:linchuming22@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=6pS2epEAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/chuminglin/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/chuming-lin-aa4967119/">LinkedIn</a> 
              </p>
            </td>
            
            <!-- <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="./figures/me.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="./figures/me.jpg" class="hoverZoomLink"></a>
            </td> -->
          </tr>
        </tbody></table>
        
<p style="text-align:left"><strong><font size="4px">Recent news</font></strong></p> 
		<ul>
		<li><p style="text-align:left">07/2021 – 2 papers on crowd counting accepted by ICCV'21 (1 Oral and 1 Poster), with the acceptance rate to be <b>25.9%</b> </p></li>
		<li><p style="text-align:left">07/2021 – Our <a href="https://arxiv.org/pdf/2003.11228.pdf"; style="color: #EE7F2D;"> <b>ASFD</b></a> on face detection is accepted by ACM MM'21 </p></li>
	    </ul>
	 
	<br>
	<p style="text-align:justify"><strong><font size="4px">Publications</font></strong> (* equal contribution, <sup>#</sup> corresponding author)
		<table id="pubList" border="0" cellpadding="0" width="100%" style="border-spacing: 10 18px; line-height:16pt; border: 0px;">

            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="./projects/AFSD_CVPR2021.png" style="height: 120px; width: 200px; margin-top: 10px">
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2103.13137">
                  <papertitle><b>Learning Salient Boundary Feature for Anchor-free Temporal Action Localization</b></papertitle>
                  </a>
                  <br>
                  C. Lin*, C. Xu*, D. Luo, Y. Wang, <b>Y. Tai</b>, C. Wang, J. Li, F. Huang and Y. Fu.              
                  <br>
                  <em>Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2021 
                  <br>
                  <a href="https://arxiv.org/abs/2103.13137"; style="color: #EE7F2D;">arXiv</a>
              /
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Learning_Salient_Boundary_Feature_for_Anchor-free_Temporal_Action_Localization_CVPR_2021_paper.pdf"; style="color: #EE7F2D;">Paper</a>
              /
              <a href="https://github.com/TencentYoutuResearch/ActionDetection-AFSD"; style="color: #EE7F2D;">Code (Official)</a>
                  </p>
                </td><tr>	

			
        </table></p>
 
		
	<p style="text-align:left"><strong><font size="4px">Awards</font></strong></p>
		<ul>
		    <li><p style="text-align:left">2021 Winner of CVPR NTIRE 2021 Challenge on Video Super-Resolution: Spatial-Temporal (Team name: Imagination)</p></li>
		</ul><br>


<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=faf9f9&w=300&t=tt&d=hvoHWGKZcyFl6zhd6aLhpusD9f4jQY_gzPG8UfsmW0I&co=1285d6'></script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha3848gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>


</body>          

</html>